../speech_llm/modular_audio_gpt_train.py --config-path=../speech_llm/conf/ --config-name modular_audio_gpt_config_cross_llama_lhotse model.perception.xattn.target=nemo.collections.multimodal.speech_llm.modules.perception.ProjectTransformerCrossAttention ++model.perception.xattn.xformer_num_layers=1 ++model.data.train_ds.num_workers=0 model.freeze_llm=false model.megatron_amp_O2=false model.optim.name=distributed_fused_adam ++model.optim.bucket_cap_mb=200 ++model.optim.overlap_grad_sync=False ++model.optim.contiguous_grad_buffer=True ++model.use_flash_attention=True model.freeze_audio_encoder=false model.pretrained_audio_model=/workspace/nemo/works/zhehuaic_works/llm/canary-1b.nemo model.restore_from_path=/workspace/nemo/works/mod_speech_llm/models/llm/llm/tiny_llama.nemo model.global_batch_size=2 model.micro_batch_size=2 ++trainer.use_distributed_sampler=false ++trainer.limit_train_batches=10 ++trainer.val_check_interval=10 ~model.peft model.perception.modality_adapter.subsampling_factor=8 model.perception.modality_adapter.reduction_factor=8 model.perception.modality_adapter.reduction=striding model.perception.modality_adapter.reduction_position=-1 ++model.perception.use_multi_layer_feat=false ++model.perception.add_sep=true ++model.perception.multi_layer_feat.layer_idx_list=[0,6,12,16,-1] ++model.perception.multi_layer_feat.aggregator.align_mode=max ++model.perception.is_canary=True ++model.perception.is_ctc=False ++model.perception.greedy_decoding_overwrite=true ++model.data.train_ds.convert_canary_prompt_to_text=true ++model.data.validation_ds.convert_canary_prompt_to_text=true ++model.data.train_ds.seed=trng ++model.data.train_ds.use_bucketing=false ++model.data.train_ds.canary_tokens_augment_ratio=0.5 ++model.data.train_ds.batch_size=2 ++model.data.train_ds.batch_duration=null ++model.data.validation_ds.max_seq_length=512 ++model.data.train_ds.add_bos=True ++model.data.validation_ds.random_context_prob=0.5 ++model.data.validation_ds.drop_last=False ++model.data.validation_ds.use_lhotse=True ++model.data.validation_ds.batch_size=2 ++model.data.validation_ds.use_bucketing=False ++model.data.validation_ds.text_field=text ++model.data.train_ds.text_field=text model.data.train_ds.manifest_filepath=[[/media/data/datasets/LibriSpeech/dev_clean_10.json,1],[/media/data/datasets/LibriSpeech/dev_clean_10.json,1]] trainer.devices=-1 ++model.tensor_model_parallel_size=2 model.data.validation_ds.manifest_filepath=[/media/data/datasets/LibriSpeech/dev_clean_10.json,/media/data/datasets/LibriSpeech/dev_clean_10.json]